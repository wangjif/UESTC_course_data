# 要求
调研报告要求：
1. 结合本课程讲授的计算机视觉或者模式识别相关领域主题进行前沿技术调研（主要调研中英文文献，文献数量不少于20篇）
2. 针对所搜集的文献内容，对所选择的技术领域进行关键技术介绍和分析（典型前沿技术方法不少于5种），对比不同技术的优缺点，并结合自身理解，总结未来技术发展的潜在方向。 

# 自动驾驶调研报告

# 引言
交通是一个国家经济发展的重要基础产业。随着人们生活水平的提高，汽车已经成为人们日常出行的重要交通工具。但是在汽车方便大众的出行的同时，也带来了交通事故数量的居高不下。传统的汽车驾驶者需要集中注意力面对周遭环境的变换，而且疲劳、天气、心理等因素也会影响驾驶者的判断和反应速度，进而产生危险。
作为未来汽车的发展方向，自动驾驶汽车拥有自主判断能力，能较大程度地减少人为失误。同时，自动驾驶汽车能更好的节能减排、减少污染[1]，有良好的应用前景。为了让自动驾驶安全运行，需要对道路上的各种物体进行识别和判断，例如车辆、行人、交通标志、灯光、车道线等。自动驾驶车辆需要对这些做出实时准确的判断。

# 调研内容

## 自动驾驶简述
自动驾驶汽车中的自动驾驶系统是多技术融合的产物。所谓自动驾驶即通过多种车载传感器（如摄像头、激光雷达、毫米波雷达、GPS、惯性传感器等）来识别车辆所处的周边环境和状态，并根据所获得的环境信息（包括道路信息、交通信息、车辆位置和障碍物信息等）自主做出分析和判断，从而自主地控制车辆运动，最终实现自动驾驶[2]。
根据车辆的智能性程度，2021年8月20日，工信部批准发布了GB/T 40429-2021《汽车驾驶自动化分级》标准[3]。该标准将自动驾驶划分为L0-L5等级，具体分级标准如表1所示。

    table1

目前自动驾驶获取周围环境信息的方式大致分为2类：摄像头、雷达。相对应的处理方式也分为基于深度学习的方式处理摄像头获取的数据和基于激光雷达点云的方式处理雷达获取的数据。
## 基于深度学习
### YOLO算法在自动驾驶的应用
2016年Redmon等人提出YOLO算法[31]，开创性的将检测问题转化为回归问题，使用卷积神经网络来直接完成目标类别的判定和边界的预测。真正意义上实现了目标的实时检测，开启了目标检测One Stage 算法的新纪元。
#### 交通标志检测
Zhang等人[4]通过添加新图像和变换图像扩展了中国交通标志数据集（CTSD），形成新的数据集CCTSDB(CSUST Chinese Traffic Sign Detection Benchmark),并在YOLOv2算法网络的中间层采用多个1×1卷积层，在顶层减少卷积层，降低计算复杂度。
Yang等[5]同样选择了CCTSDB数据集，分别使用YOLOv3和YOLOv4训练训练集。通过测试对比为其在数据集测试中IoU的变化（如图2），YOLOv4在目标检测方面优于YOLOv3。
Dewi等[6]则使用生成式对抗网络 (Generative Adversarial Networks，GAN) 生成更逼真和多样化的交通标志的训练图片，将合成图像与原始图像相结合，以增强数据集并验证合成数据集的有效性。使用Yolo、Yolo v3 和 Yolo v4 迭代。图像混合后识别性能得到了提升，在 Yolo v3 上mAP(平均精度值)为 84.9%，在 Yolo v4 mAP为 89.33%。
Mohd-Isa等[7]通过在YOLOv3 框架中包含空间金字塔池化（SPP），进一步识别真实环境中的远小交通标志。
Mangshor等[8]使用YOLO训练模型以进行识别五种警示交通标志，包括十字路口、右十字路口、左十字路口、马来西亚交通标志的学童横穿和碰撞。实时物体检测的测试结果在交通标志检测和识别上都达到了 96.00% 的准确率。
吕禾丰等[9]调整了YOLO v5算法的损失函数，使用EIOU(Efficient Intersection over Union)损失函数代替 GIOU (Generalized Intersection over Union)损失函数来提高算法的精度，实现对目标更快速的识别；使用Cluster NMS (Non-Maximum suppression)代替WeightedNMS算法，提高生成检测框的准确率。
#### 交通灯检测
Jensen等[10]应用了实时目标检测系统YOLO，检测公共LISA交通灯数据集，该数据集包含大量在不同光照和天气条件下捕获的带标签的交通灯，达到了90%的准确率。
Possatti等[11]使用YOLOv3模型，与智能汽车使用的先验地图相结合，识别预定义路线的相关交通灯。该实验的数据集分类过程中只考虑了两类对象：红-黄和绿交通灯。通过混合红色和黄色信号灯的方式，克服黄色样品的不足，实现实时的现实的交通信号灯的检测。
Gao等[12]使用YOLOv3和YOLOv4算法对道路上的交通信号图像进行检测和识别实验，结果表明，YOLOv4网络的准确率高于YOLOv3网络。
#### 交通车辆检测
叶佳林等[45]在YOLO v3框架下，设计特征融合结构和采用GIOU损失函数，降低非机动车漏检率，提高定位准确度。Zhou等[46]将毫米波雷达与摄像机信息融合，利用时空同步关联多传感器数据，通过YOLO v2算法实现深度融合对车辆的目标检测识别。张成标等[47]改动原YOLOv2网络框架,添加改进的残差网络（如图3）和Kelu激活函数来提高检测准确率,添加多尺度层来提升对图片中不同尺寸目标的检测精度。
Chen等人[48]提出YOLO v3-live，是在Tiny-YOLOv3的网络层结构上进行裁剪，量化网络中的网络参数，这种方式降低了嵌入式设备的计算复杂度，速度得到提升可以达到28FPS，但是在同样的数据集上，mAP降低了18%。Wu等[49]在YOLO v5s神经网络结构的基础上，提出了YOLO v5-Ghost。调整了YOLO v5s 的网络层结构。计算复杂度降低，更适合嵌入式设备。用该结构实现车辆和距离的实时检测，YOLO v5-Ghost的检测速度提高19 FPS，但是mAP降低3%。
#### 行人检测
Lan等人[50]在YOLO v2的网络结构中，将穿透层连接数从16层改为12层，检测速度得到提升,同时由实验结果看降低了漏检率（Miss Rate）（如图4）。
高宗等人[51]提出在原有的YOLO网络结构中，结合行人在图像中表现出小纵横比的特点，通过聚类选择合适数量和规格的候选帧，改变YOLO网络结构，调整候选帧在X轴和Y轴方向的分布密度，形成适合行人检测的网络结构。但是该方法将行人检测视为二分类问题，使得在行人动态变化的检测方面具有较大局限性。
郝旭政等[52]提出了一种基于深度残差网络和YOLO模型的行人检测与识别方法。Zhang等[53]的 Caps-YOLO检测模型则基于YOLO v3，该模型采用dense connection代替了原有网络中的shortcut connection，构造了dense block组件，提高了feature map的利用率。同时采用向量神经元结合动态路由机制来实现该模型的检测功能，降低漏检和误检姿态复杂的行人的概率，在不同的数据集上精度提升1.81%-6.63%不等。Liu等[54]采用K-means聚类方法直接计算anchor使用数据集的帧大小。通过引入SE模块（Squeeze-and-Excitation Networks，SENet）和集成DIOU（Distance-IoU）损失函数。提高对智能驾驶系统中小尺度行人目标的检测精度。
Zhang等[55]基于tiny-yolov3网络提出了在原有网络的基础上增加了三层卷积，提高了模型提取特征的能力；引入了1*1卷积核对特征进行降维，减少加深模型引起的计算量，保证了检测的实时性，但是仍存在漏检，小目标的识别不够准确问题。
#### 车道线的检测
Zhang等人[56]构建了一个基于YOLO v3的两阶段学习网络，对YOLO v3算法的结构参数进行了修改，采用基于Canny算子的自适应边缘检测算法对第一阶段模型检测到的车道进行重新定位，并将处理的图像作为标签数据用于第二阶段模型的训练，提高复杂场景下车道检测的准确性。图5显示了 KITTI 和 Caltech数据集上的 P-R（精确召回）曲线的结果。基于YOLO系列的检测算法在车道检测方面优势明显，尤其是基于YOLO v3的S×2S结构模型表现最好。
崔文靓等人[57]在原YOLO v3的基础上，利用K-means++聚类算法优化网络anchor参数, 并改进YOLOv3算法卷积层结构，使最终结果较原始算法平均检测准确率提升了11%。
Ji等人[58]根据车道线图纵向和横向分布密度不一致的特点，将车道线图划分为S×2S网格，并简化网络将原Yolo v3算法中的卷积层从53层调整为49层，以及对簇中心距离和损失函数等参数进行了改动。最终平均检测准确率为92.03%，处理速度为48 fps，该改动更适合于3车道线等小目标的检测。
张翔[59]同样采用S×2S网格密度的YOLO v3算法，并在双向循环门限单元(bidirectional gated recurrent unit,BGRU)的基础上，提出基于车道线分布关系的车道线检测模型(BGRU-Lane, BGRU-L)。最后利用基于置信度的D-S(Dempster-Shafer)算法融合YOLO v3(S×2S)和BGRU-L的检测结果，提高了模型检测小尺寸、大宽高比物体的准确度。
### CycleGAN模型
CycleGAN模型是一种无监督的模型[13]，用于生成训练集。它可以更好的提升模型跨域检测的精度和模型的迁移能力，可以完成从源数据域到目标数据域的风格转换。
CycleGAN模型包含2个生成器网络和2个判别器网络，其中，2个生成器网络的作用是将输入的源数据域、目标数据域中的图像分别得到其对应的合成图像，通过不断地训练生成器使其合成的图像与对应目标域中的真实图像相似度尽可能高，以骗过判别器使其无法区分该图像是合成图还是真实图。
2个判别器网络的作用是将生成器得到的合成图与原数据域中的真实图像区分开，对于真实图像尽可能输出一个较高的分数(接近于1),对于合成图尽可能输出一个较低的分数(接近于0),因此，判别器不会被生成器生成的‘假图’所蒙骗，能够更好地区分真实图和合成图。

## 基于激光雷达点云
### 单阶段检测算法
单阶段算法指的是从原始的点云中提取特征，使用这些提取的特征直接进行预测并输出结果。这种算法一般来说运行速度快，但是精度欠佳。
#### 基于体素的检测算法
基于体素的检测算法的基本思想是，将原始的点云通过变换后通过体素进行表示，之后通过骨干网络对体素进行特征提取。例如，在VoxelNet[5]网络中，原始的点云数据首先根据点云的(X,Y,Z)坐标被划分为若干体素，对划分后的点云进行特征编码，然后生成对应的特征图，通过在骨干网络中使用3D卷积对特征图进行特征提取，最后3D检测头将根据获得到的特征进行目标预测并生成相应的边界框。由于点云的稀疏性，为了提高检测效率，SECOND[6]在VoxelNet[5]网络的基础上，在骨干网络中使用了文献[7]提出的Sparse Convolution Layer进行特征提取。PointPillars[8]则是在点云表示阶段仅根据点云的(X,Y)坐标进行划分，将原始的点云划分为若干点柱，然后使用PointNet[9]网络来获取的点柱特征投影到(X,Y)平面，生成伪图，然后使用2D卷积神经网络（Convolutional Neural Networks,CNN）对伪图进行卷积。通过使用2D CNN，该方法在检测速度上获得了巨大的提升。TANet[10]网络将单帧点云以体素表示，并在特征编码阶段加入了注意力机制，获取了检测性能的提高。而3D-MAN[11]算法则在PointPillars[8]的基础上，在多帧点云中加入注意力机制，来提高模型的性能。AFDet[12]算法在PointPillars中加入了无锚框检测头，类似地，AFDetV2[13]算法在VoxelNet[5]网络的基础上提出了无锚框的检测方法。VoTr[14]提出了一种体素transformer的方法。MVF[15]对点云采用动态体素划分方法，将鸟瞰图视角（BEV）和透视图视角（Perspective view）下获取的点云特征相融合，来丰富点云的特征。
#### 基于点的检测算法
顾名思义，基于点的检测算法将直接使用原始的点云作为网络的输入并提取出点特征，用于目标检测。3DSSD[16]提出了一种融合采样方法，通过Distance-FPS和Feature-FPS代替了传统的特征传播层（Feature Propagation layers）从而提高模型的运行效率。之后获得的特征将作为候选生成层（Candidate Generation layer）的输入，最后使用无锚框检测头生成预测结果。
#### 基于图的检测方法
Point-GNN[17]网络使用图来表示点云，首先使用体素对点云进行下采样，利用下采样后的点云特征作为节点，通过多层感知机（Multilayer Perceptron,MLP）来提取边特征并迭代更新节点的特征，最后利用迭代后获取的点云特征作为检测头的输入来生成检测结果。SVGA-Net[18]网络通过将原始点云划分为球形体素，然后在体素内部点云和球形体素间分别构建局部和全局图，并融入注意力机制，来获取更加丰富的特征表达，从而提升模型的目标检测性能。
### 两阶段检测算法
两阶段检测方法是使用第二阶段的网络从第一阶段生成的区域提案中进行更精确的检测[4]，因此两阶段检测算法也被称为基于区域提案的方法。两阶段检测方法在运行速度上较慢，但是却可以获得相较单阶段检测算法更好的检测性能。
PointVoxel-RCNN[25](PV-RCNN）算法首先将点云划分为若干球形体素，之后使用3D稀疏卷积网络以及基于PointNet[9]的网络来提取点云特征。具体来说，体素化的点云将通过3D稀疏卷积网络生成多尺度的语义信息，并生成3D目标提议。除此之外，通过体素集抽象模块将把学习到的体素特征编码为一组关键点。最后关键点特征将作为keypoint-to-grid ROI abstraction模块的输入，来获得更加丰富的信息。这些信息将被用于优化之前生成的3D目标提议，提升检测的精确度。Centerpoint[26]受到2D目标检测方法CenterNet[27]的启发，对VoxelNet[5]和PointPillars[8]进行了改进，提出了Center heatmap head，该方法取得了很好的检测性能。Part-A*2[28]由部分感知阶段和部分聚合阶段组成。部分感知阶段使用了带有稀疏卷积和稀疏反卷积的U-Net[29]网络来学习点特征，通过点特征来进行预测并生成粗略的内部对象位置。在部分聚合阶段将通过RoI(Region of Interest)感知池化对预测阶段生成的位置信息进行聚合，从而优化3D检测框。Fast Point R-CNN[30]是一种使用点和体素处理点云的二阶段检测方法。具体来说，原始点云将被体素化，之后使用3D骨干网络来生成初始的检测结果；之后使用第一阶段生成的检测框内部的点的特征对检测框的精度进行提升。Voxel R-CNN[31]首先将点云进行体素化，使用3D卷积对体素进行采样，之后将3D点云特征转换为鸟瞰图，使用2D卷积提取特征并生成一阶段的检测结果。在第二阶段时，使用体素RoI池化从3D点云特征中提取RoI特征，最后利用RoI特征来优化一阶段的检测结果。STD[32]是一种基于PointNet[9]和PointNet++[33]的方法，首先在提案生成模块生成球形锚框，在第二阶段使用每个点的语义分数去除冗余的锚框，从而获得更好的检测结果。3D IOU-Net[34]使用PointNet++[33]获取点云特征并生成一阶段的提案，在二阶段通过IoU对齐操作优化一阶段的检测结果。文献[35]提出了一种实例感知的IoU池化模块，用于对一阶段生成的检测结果进行优化。文献[36]提出了一种新的局部优化网络，在二阶段生成优化的预测结果。RSN[37]提出范围稀疏网络，首先使用2D卷积从范围图（range image）中提取特征，之后使用稀疏卷积从范围图的前景点中进一步提取点特征，最后使用稀疏CenterNet[27]来生成3D检测框。LiDAR R-CNN[38]也提出了一种新的二阶段检测方法。CT3D[39]提出了一种通道级的transformer网络用于二阶段的优化。

# 结语

# 参考文献
[1] LUETTEL T, HIMMELSBACH M, WUENSCHE H-J. Autonomous ground vehicles—Concepts and a path to e[J]. Proceedings of the IEEE, 2012, 100(Special Centennial Issue):1831-1839.
[2] 申泽邦，雍宾宾，周庆国，李良. ⽆⼈驾驶原理与实践[M]. 北京：机械⼯业出版社, 2019.
[3]全国汽车标准化技术委员会. GB/T 40429-2021《汽车驾驶自动化分级》正式发布 [EB/OL].(2021-09-11) [2021-12-05]. http://www.catarc.org. cn/xinwen/show-3334.html.National Automotive Standardization Technical Committee. GB/T 40429-2021 "Automotive Driving Automation Classification" officially released[EB/OL]. (2021-09-11) [2021-12-05].
[4] ZHANG J, HUANG M, JIN X, et al. A real- time chinese traffic sign detection algorithm based on modified YOLOv2[J]. Algorithms, 2017, 10(4):127.
[5] YANG W, ZHANG W. Real-time Traffic Signs Detection Based on YOLO Network Model[C] //2020 International Conference on Cyber- Enabled Distributed Computing and Knowledge Discovery (CyberC). Chongqing, China.29-30 Oct. 2020 IEEE, 2020:354-357.
[6] DEWI C, CHEN R-C, LIU Y-T, et al. Yolo V4 for advanced traffic sign recognition with synthetic training data generated by various GAN[J]. IEEE Access, 2021, 9:97228-97242
[7] MOHD-ISA W-N, ABDULLAH M-S, SARZIL M, et al. Detection of Malaysian Traffic Signs via Modified YOLOv3 Algorithm[C]//2020 International Conference on Data Analytics for Business and Industry: Way Towards a Sustainable Economy (ICDABI). Sakheer, Bahrain.26-27 Oct. 2020. IEEE,2020:1-5.
[8]MANGSHORNNA,PAUDZINPAM, IBRAHIM S, et al. A Real-Time Malaysian Traffic Sign Recognition Using YOLO Algorithm[C]//Proceedings of the 12th National Technical Seminar on Unmanned System Tech- nology 2020. Springer, Singapore, 2022:283-293.
[9]吕禾丰, 陆华才. 基于 YOLOv5 算法的交通标 志识别技术研究[J]. 电子测量与仪器学报,2021, 35(10):137-144.LYU H F, LU H C. Research on Traffic Sign Recognition Technology Based on YOLOv5 Algorithm[J]. Journal of Electronic Measurement and Instrumentation, 2021, 35(10):137-144.
[10] JENSEN M B, NASROLLAHI K, MOESLUND T B. Evaluating state-of-the-art object detector on challenging traffic light data[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, 2017:9-15.
[11] POSSATTI L C, GUIDOLINI R, CARDOSO V B, et al. Traffic light recognition using deep learning and prior maps for autonomous cars[C] //2019 international joint conference on neural networks (IJCNN). Budapest, Hungary.14-19 July 2019. IEEE, 2019:1-8.
[12] GAO H, WANG W, YANG C, et al. Traffic signal image detection technology based on YOLO[C]//Journal of Physics: Conference Series. IOP Publishing, Guangzhou, China , 2021: 012012.

[13]范佳琦,李鑫,霍天娇,洪金龙,高炳钊,陈虹.基于单阶段算法的智能汽车跨域检测研究[J].中国公路学报,2022,35(03):249-262.DOI:10.19721/j.cnki.1001-7372.2022.03.021.